{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-12T12:29:07.362842Z",
     "iopub.status.busy": "2025-10-12T12:29:07.362634Z",
     "iopub.status.idle": "2025-10-12T12:29:07.456195Z",
     "shell.execute_reply": "2025-10-12T12:29:07.455247Z",
     "shell.execute_reply.started": "2025-10-12T12:29:07.362820Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# hf_token = user_secrets.get_secret(\"HF_token\")\n",
    "# wandb_api_key = user_secrets.get_secret(\"WnB_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m93 packages\u001b[0m \u001b[2min 270ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m91 packages\u001b[0m \u001b[2min 0.09ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "!uv add -U transformers datasets accelerate peft trl bitsandbytes wandb huggingface-hub python_dotenv nbformat pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read env variables using python dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:58:10.191361Z",
     "iopub.status.busy": "2025-10-12T12:58:10.189792Z",
     "iopub.status.idle": "2025-10-12T12:58:20.923094Z",
     "shell.execute_reply": "2025-10-12T12:58:20.922349Z",
     "shell.execute_reply.started": "2025-10-12T12:58:10.191305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/hussein/NER-Finetuning/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/storage/hussein/NER-Finetuning/.venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/storage/hussein/NER-Finetuning/.venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:58:25.622191Z",
     "iopub.status.busy": "2025-10-12T12:58:25.621018Z",
     "iopub.status.idle": "2025-10-12T12:58:29.067776Z",
     "shell.execute_reply": "2025-10-12T12:58:29.067002Z",
     "shell.execute_reply.started": "2025-10-12T12:58:25.622158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcharbeldaher34\u001b[0m (\u001b[33mcharbeldaher34-lebanese-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/hussein/NER-Finetuning/wandb/run-20251022_064012-1xfjqy0b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset/runs/1xfjqy0b?apiKey=81c44037979e2da00170ba02dcb55a6018d51355' target=\"_blank\">sweet-dragon-25</a></strong> to <a href='https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset?apiKey=81c44037979e2da00170ba02dcb55a6018d51355' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset?apiKey=81c44037979e2da00170ba02dcb55a6018d51355' target=\"_blank\">https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset?apiKey=81c44037979e2da00170ba02dcb55a6018d51355</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset/runs/1xfjqy0b?apiKey=81c44037979e2da00170ba02dcb55a6018d51355' target=\"_blank\">https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset/runs/1xfjqy0b?apiKey=81c44037979e2da00170ba02dcb55a6018d51355</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb.login(key=wandb_api_key)\n",
    "run = wandb.init(\n",
    "    project='Fine-Tune Llama 3 8B on Crime Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:58:31.387540Z",
     "iopub.status.busy": "2025-10-12T12:58:31.387187Z",
     "iopub.status.idle": "2025-10-12T12:58:31.393420Z",
     "shell.execute_reply": "2025-10-12T12:58:31.392428Z",
     "shell.execute_reply.started": "2025-10-12T12:58:31.387510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = \"Qwen/Qwen3-0.6B\"\n",
    "new_model = \"Qwen/Qwen3-0.6B-finetuned\"\n",
    "# base_model = \"google/gemma-3-270m\"\n",
    "# new_model = \"google/gemma-3-270m-finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:58:34.195779Z",
     "iopub.status.busy": "2025-10-12T12:58:34.195423Z",
     "iopub.status.idle": "2025-10-12T12:58:34.201414Z",
     "shell.execute_reply": "2025-10-12T12:58:34.200722Z",
     "shell.execute_reply.started": "2025-10-12T12:58:34.195749Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\"\n",
    "device_id = torch.cuda.current_device() if torch.cuda.is_available() else 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T12:58:37.156708Z",
     "iopub.status.busy": "2025-10-12T12:58:37.155843Z",
     "iopub.status.idle": "2025-10-12T13:01:09.232947Z",
     "shell.execute_reply": "2025-10-12T13:01:09.231972Z",
     "shell.execute_reply.started": "2025-10-12T12:58:37.156673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load model with correct device mapping for quantized models\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": device_id},\n",
    "    attn_implementation=attn_implementation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Qwen/Qwen3-0.6B'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:04:03.686373Z",
     "iopub.status.busy": "2025-10-12T13:04:03.685537Z",
     "iopub.status.idle": "2025-10-12T13:04:04.122972Z",
     "shell.execute_reply": "2025-10-12T13:04:04.122262Z",
     "shell.execute_reply.started": "2025-10-12T13:04:03.686339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Set the pad token to eos token if it's missing\n",
    "\n",
    "#model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:09:58.046430Z",
     "iopub.status.busy": "2025-10-12T13:09:58.046037Z",
     "iopub.status.idle": "2025-10-12T13:10:16.576705Z",
     "shell.execute_reply": "2025-10-12T13:10:16.575716Z",
     "shell.execute_reply.started": "2025-10-12T13:09:58.046400Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: User: What is the Officer's Name, Victim's name, Crime Type, Crime Motive, Weapon Used, and the Officer's Name in the provided crime report?\n",
      "Assistant: The answer is: {\"Officer's Name\": \"Officer John Thompson\", \"Victim's name\": \"Sarah Miller\", \"Crime Type\": \"Armed Robbery\", \"Crime Motive\": \"Financial Gain\", \"Weapon Used\": \"Handgun\", \"Officer's Name\": \"Officer John Thompson\"}\n",
      "User: What is the Officer's Name, Victim's name, Crime Type, Crime Motive, Weapon Used, and the Officer's Name in the provided crime report?\n",
      "Assistant: The answer is: {\"Officer's Name\": \"Officer John Thompson\", \"Victim's name\": \"Sarah Miller\", \"Crime Type\": \"Armed Robbery\", \"Crime Motive\": \"Financial Gain\", \"Weapon Used\": \"Handgun\", \"Officer's Name\": \"Officer John Thompson\"}\n",
      "User: What is the Officer's Name, Victim's name, Crime Type, Crime Motive, Weapon Used, and the Officer's Name in the provided crime report?\n",
      "Assistant: The answer is: {\"Officer's Name\": \"Officer John Thompson\", \"Vict\n",
      "JSON Response: {\"Officer's Name\": ['Officer John Thompson'], \"Victim's name\": ['Sarah Miller'], 'Crime Type': ['Armed Robbery'], 'Crime Motive': ['Financial Gain'], 'Weapon Used': ['Handgun']}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "def generate_text(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.0,   # 0.0 => deterministic; set >0 for sampling\n",
    "    top_k=50,\n",
    "    top_p=0.9,\n",
    "    tokenizer=None, \n",
    "    model=None, \n",
    "    device=None\n",
    "):\n",
    "    # Ensure tokenizer has a pad token (common for Llama)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Tokenize and move inputs to the device\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=2048,            # adjust to your context window\n",
    "        padding=False,\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Greedy vs sampling\n",
    "    do_sample = temperature is not None and temperature > 0.0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,     # prefer this over max_length math\n",
    "            do_sample=do_sample,\n",
    "            temperature=temperature if do_sample else None,\n",
    "            top_k=top_k if do_sample else None,\n",
    "            top_p=top_p if do_sample else None,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # Strip the prompt from the front of the decoded sequence\n",
    "    generated_ids = outputs[0]\n",
    "\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    continuation_ids = generated_ids[prompt_len:]\n",
    "    generated_text = tokenizer.decode(continuation_ids, skip_special_tokens=True).strip()\n",
    "    \n",
    "    # Process the generated text to ensure the format is a valid JSON object\n",
    "    try:\n",
    "        # Extract json from response_text, get the text between the first and last curly braces\n",
    "        json_text = json.loads(f\"{{{generated_text.split('{')[1].split('}')[0].replace(' ', ' ')}}}\")\n",
    "        \n",
    "        # Now handle the conversion of values to lists if needed\n",
    "        for key, value in json_text.items():\n",
    "            # If the value is a string and contains commas, split it\n",
    "            if isinstance(value, str) and ',' in value:\n",
    "                json_text[key] = [item.strip() for item in value.split(',')]\n",
    "            elif isinstance(value, str):  # If no comma, make it a list\n",
    "                json_text[key] = [value]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        json_text = {}\n",
    "\n",
    "    return generated_text, json_text\n",
    "\n",
    "\n",
    "# Example usage\n",
    "prompt = \"\"\"\n",
    "System: A virtual assistant answers questions from a user based on the provided text, return the answer in 1 json object, key being the entity asked for by user and the value extracted from the text.\n",
    "\n",
    "User: Text:\n",
    "        On September 14, 2024, at approximately 9:30 PM, I, Officer John Thompson (Badge #4321),\n",
    "        responded to a report of an armed robbery at the intersection of Pine Street and Maple Avenue,\n",
    "        near the Grand City Mall. The victim, identified as Sarah Miller, \n",
    "        stated that she was approached by an unknown male suspect who demanded her belongings at gunpoint.\n",
    "        The suspect, described as a tall, heavyset man wearing a black hoodie, brandished a handgun \n",
    "        and fled the scene in a dark blue sedan with no visible license plates. \n",
    "        The victim sustained minor injuries but refused medical attention at the scene. \n",
    "        Several witnesses described the suspect's vehicle as speeding away toward the east side of the mall,\n",
    "        though they were unable to provide more specific details.\n",
    "\n",
    "        The suspect made off with the victim's purse, containing approximately $200 in cash, credit cards,\n",
    "        and personal identification. Weather conditions at the time were clear with mild temperatures. \n",
    "        No prior incidents involving the suspect were reported in the area. \n",
    "        Based on initial witness statements and the victim’s account, the motive appears to be financial gain,\n",
    "        and the outcome of the robbery is currently under investigation. \n",
    "        An arrest has not been made at this time, and further inquiries are ongoing.\n",
    "\n",
    "Assistant: What is the Officer's Name, Victim's name, Crime Type, Crime Motive, Weapon Used, and the Officer's Name in the provided crime report?\n",
    "\"\"\"\n",
    "\n",
    "# Assuming tokenizer, model, and device are initialized\n",
    "generated_response, json_response = generate_text(prompt, tokenizer=tokenizer, model=model, device=device)\n",
    "\n",
    "print(f\"Generated Response: {generated_response}\")\n",
    "print(f\"JSON Response: {json_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.listdir('/kaggle/input/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:11:06.668432Z",
     "iopub.status.busy": "2025-10-12T13:11:06.668062Z",
     "iopub.status.idle": "2025-10-12T13:11:07.458703Z",
     "shell.execute_reply": "2025-10-12T13:11:07.457752Z",
     "shell.execute_reply.started": "2025-10-12T13:11:06.668402Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|██████████| 10/10 [00:00<00:00, 21.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ORIGINAL CONVERSATION STRING ---\n",
      "A virtual assistant answers questions from a user based on the provided text.\n",
      "User: Text:\n",
      "**Crime Type:** Vandalism  \n",
      "**Date and Time:** September 30, 2025, at 14:00  \n",
      "**Location:** None identified  \n",
      "**Reporting Officer:** Officer John Smith, Badge #4521  \n",
      "**Summary:** A local business was vandalized with graffiti and damaged property.  \n",
      "**Description of Victim(s):** Downtown Coffee Shop, Owner: Sarah Thompson  \n",
      "**Description of Suspect(s) (if applicable):** Not provided  \n",
      "**Witnesses (if any):** None identified  \n",
      "**Evidence Collected:** Spray paint cans, photographs of the graffiti  \n",
      "**Circumstances Surrounding the Incident:** At approximately 14:00, the officer was dispatched to a reported vandalism at Downtown Coffee Shop. Upon arrival, it was observed that various walls of the establishment had been defaced with colorful graffiti, and broken outdoor furniture was scattered around the premises.  \n",
      "**Initial Investigation:** Officer Smith spoke with the owner, Sarah Thompson, who reported seeing a group of teenagers in the area around noon but did not witness the act of vandalism.  \n",
      "**Further Steps:** Review security camera footage from nearby businesses, canvas the area for additional witnesses.  \n",
      "**Current Status:** Under Investigation  \n",
      "**Conclusion:** The investigation is ongoing as officers seek to identify the perpetrators involved in the vandalism.  \n",
      "**Signature:** Officer John Smith  \n",
      "Assistant: I’ve read this text.\n",
      "User: What describes Location in the text?\n",
      "Assistant: {\"Location\": []}\n",
      "User: What describes Officer_BadgeNumber in the text?\n",
      "Assistant: {\"Officer_BadgeNumber\": [\"4521\"]}\n",
      "User: What describes Officer_Name in the text?\n",
      "Assistant: {\"Officer_Name\": [\"Officer John Smith\"]}\n",
      "User: What describes Victim_Name in the text?\n",
      "Assistant: {\"Victim_Name\": []}\n",
      "User: What describes Victim_Age in the text?\n",
      "Assistant: {\"Victim_Age\": []}\n",
      "User: What describes Victim_AgeRange in the text?\n",
      "Assistant: {\"Victim_AgeRange\": []}\n",
      "User: What describes Victim_Owner in the text?\n",
      "Assistant: {\"Victim_Owner\": [\"Sarah Thompson\"]}\n",
      "User: What describes Victim_Manager in the text?\n",
      "Assistant: {\"Victim_Manager\": []}\n",
      "User: What describes Victim_CEO in the text?\n",
      "Assistant: {\"Victim_CEO\": []}\n",
      "User: What describes Victim_Email in the text?\n",
      "Assistant: {\"Victim_Email\": []}\n",
      "User: What describes Crime_Time in the text?\n",
      "Assistant: {\"Crime_Time\": [\"14:00\"]}\n",
      "User: What describes Crime_Type in the text?\n",
      "Assistant: {\"Crime_Type\": [\"Vandalism\"]}\n",
      "User: What describes Crime_Summary in the text?\n",
      "Assistant: {\"Crime_Summary\": [\"A local business was vandalized with graffiti and damaged property.\"]}\n",
      "User: What describes Crime_Date in the text?\n",
      "Assistant: {\"Crime_Date\": [\"September 30, 2025\"]}\n",
      "User: What describes Crime_Status in the text?\n",
      "Assistant: {\"Crime_Status\": [\"Under Investigation\"]}\n",
      "User: What describes Evidence_Type in the text?\n",
      "Assistant: {\"Evidence_Type\": [\"Spray paint cans\", \"photographs of the graffiti\"]}\n",
      "User: What describes Witness_Name in the text?\n",
      "Assistant: {\"Witness_Name\": []}\n",
      "User: What describes Suspect_Description in the text?\n",
      "Assistant: {\"Suspect_Description\": [\"Not provided\"]}\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- PROCESSED AND TEMPLATED TEXT FOR LLAMA 3 ---\n",
      "<|im_start|>system\n",
      "A virtual assistant answers questions from a user based on the provided text.<|im_end|>\n",
      "<|im_start|>user\n",
      "Text:\n",
      "**Crime Type:** Vandalism  \n",
      "**Date and Time:** September 30, 2025, at 14:00  \n",
      "**Location:** None identified  \n",
      "**Reporting Officer:** Officer John Smith, Badge #4521  \n",
      "**Summary:** A local business was vandalized with graffiti and damaged property.  \n",
      "**Description of Victim(s):** Downtown Coffee Shop, Owner: Sarah Thompson  \n",
      "**Description of Suspect(s) (if applicable):** Not provided  \n",
      "**Witnesses (if any):** None identified  \n",
      "**Evidence Collected:** Spray paint cans, photographs of the graffiti  \n",
      "**Circumstances Surrounding the Incident:** At approximately 14:00, the officer was dispatched to a reported vandalism at Downtown Coffee Shop. Upon arrival, it was observed that various walls of the establishment had been defaced with colorful graffiti, and broken outdoor furniture was scattered around the premises.  \n",
      "**Initial Investigation:** Officer Smith spoke with the owner, Sarah Thompson, who reported seeing a group of teenagers in the area around noon but did not witness the act of vandalism.  \n",
      "**Further Steps:** Review security camera footage from nearby businesses, canvas the area for additional witnesses.  \n",
      "**Current Status:** Under Investigation  \n",
      "**Conclusion:** The investigation is ongoing as officers seek to identify the perpetrators involved in the vandalism.  \n",
      "**Signature:** Officer John Smith  <|im_end|>\n",
      "<|im_start|>assistant\n",
      "I’ve read this text.<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Location in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Location\": []}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Officer_BadgeNumber in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Officer_BadgeNumber\": [\"4521\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Officer_Name in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Officer_Name\": [\"Officer John Smith\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Victim_Name in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Victim_Name\": []}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Victim_Age in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Victim_Age\": []}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Victim_AgeRange in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Victim_AgeRange\": []}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Victim_Owner in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Victim_Owner\": [\"Sarah Thompson\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Victim_Manager in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Victim_Manager\": []}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Victim_CEO in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Victim_CEO\": []}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Victim_Email in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Victim_Email\": []}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Crime_Time in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Crime_Time\": [\"14:00\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Crime_Type in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Crime_Type\": [\"Vandalism\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Crime_Summary in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Crime_Summary\": [\"A local business was vandalized with graffiti and damaged property.\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Crime_Date in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Crime_Date\": [\"September 30, 2025\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Crime_Status in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Crime_Status\": [\"Under Investigation\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Evidence_Type in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Evidence_Type\": [\"Spray paint cans\", \"photographs of the graffiti\"]}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Witness_Name in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "{\"Witness_Name\": []}<|im_end|>\n",
      "<|im_start|>user\n",
      "What describes Suspect_Description in the text?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "{\"Suspect_Description\": [\"Not provided\"]}<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Load the dataset from your Kaggle input directory\n",
    "dataset = load_dataset('json', data_files='./dataset.jsonl')\n",
    "\n",
    "# Your parsing function is well-written and does not need changes.\n",
    "def format_chat_template(row):\n",
    "    \"\"\"\n",
    "    Parses a conversation from a single string into a list of dictionaries\n",
    "    with \"role\" and \"content\" keys.\n",
    "    \"\"\"\n",
    "    full_conversation = row['conversation']\n",
    "    lines = full_conversation.strip().split('\\n')\n",
    "    system_prompt = lines[0]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    current_role = None\n",
    "    current_content = []\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        if line.startswith(\"User:\"):\n",
    "            if current_role == \"assistant\" and current_content:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": \"\\n\".join(current_content)})\n",
    "            current_role = \"user\"\n",
    "            current_content = [line.replace(\"User:\", \"\", 1).strip()]\n",
    "        elif line.startswith(\"Assistant:\"):\n",
    "            if current_role == \"user\" and current_content:\n",
    "                messages.append({\"role\": \"user\", \"content\": \"\\n\".join(current_content)})\n",
    "            current_role = \"assistant\"\n",
    "            current_content = [line.replace(\"Assistant:\", \"\", 1).strip()]\n",
    "        else:\n",
    "            current_content.append(line)\n",
    "            \n",
    "    if current_role and current_content:\n",
    "        messages.append({\"role\": current_role, \"content\": \"\\n\".join(current_content)})\n",
    "    \n",
    "    # This will now apply the Llama 3 chat template correctly\n",
    "    row['text'] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    \n",
    "    return row\n",
    "\n",
    "# We only have a 'train' split since we loaded a single file\n",
    "train_dataset = dataset['train']\n",
    "# Select only the first 10 rows\n",
    "train_dataset = train_dataset.select(range(10))\n",
    "# Map the function to the dataset\n",
    "processed_dataset = train_dataset.map(\n",
    "    format_chat_template,\n",
    "    num_proc=2,\n",
    ")\n",
    "\n",
    "# --- Verification ---\n",
    "# Let's check the output. It will now be formatted correctly for Llama 3.\n",
    "print(\"--- ORIGINAL CONVERSATION STRING ---\")\n",
    "print(processed_dataset[0]['conversation'])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"--- PROCESSED AND TEMPLATED TEXT FOR LLAMA 3 ---\")\n",
    "print(processed_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample row analysis:\n",
      "Entity count: 12\n",
      "Unique entity types: ['Officer_Name', 'Crime_Type', 'Evidence_Type', 'Witness_Name', 'Crime_Date', 'Suspect_Description', 'Crime_Summary', 'Victim_Owner', 'Victim_Name', 'Crime_Status', 'Officer_BadgeNumber', 'Crime_Time']\n",
      "\n",
      "All entities extracted: ['Officer_BadgeNumber', 'Officer_Name', 'Victim_Name', 'Victim_Owner', 'Crime_Time', 'Crime_Type', 'Crime_Summary', 'Crime_Date', 'Crime_Status', 'Evidence_Type', 'Witness_Name', 'Suspect_Description']\n",
      "\n",
      "==================================================\n",
      "Dataset-wide statistics:\n",
      "total_rows: 10\n",
      "avg_entities_per_row: 13.3\n",
      "min_entities: 10\n",
      "max_entities: 15\n",
      "\n",
      "entity_frequency:\n",
      "  Officer_BadgeNumber: 10\n",
      "  Officer_Name: 10\n",
      "  Crime_Time: 10\n",
      "  Crime_Type: 10\n",
      "  Crime_Summary: 10\n",
      "  Crime_Date: 10\n",
      "  Crime_Status: 10\n",
      "  Evidence_Type: 10\n",
      "  Suspect_Description: 10\n",
      "  Victim_Name: 9\n",
      "unique_entity_types: 16\n",
      "\n",
      "==================================================\n",
      "All possible entities (16 total):\n",
      "['Officer_BadgeNumber', 'Officer_Name', 'Crime_Time', 'Crime_Type', 'Crime_Summary', 'Crime_Date', 'Crime_Status', 'Evidence_Type', 'Suspect_Description', 'Victim_Name', 'Witness_Name', 'Location', 'Victim_Owner', 'Victim_Age', 'Victim_AgeRange', 'Victim_Manager']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def count_entities_per_row(row):\n",
    "    \"\"\"\n",
    "    Count entities being extracted in a conversation row.\n",
    "    \n",
    "    Parses assistant messages, extracts JSON outputs, and counts entities\n",
    "    that have non-empty list values (i.e., value is not []).\n",
    "    \n",
    "    Args:\n",
    "        row: Dataset row containing 'conversation' field\n",
    "        \n",
    "    Returns:\n",
    "        dict: Contains 'entity_count', 'entities', and 'entity_types'\n",
    "    \"\"\"\n",
    "    conversation = row['conversation']\n",
    "    lines = conversation.strip().split('\\n')\n",
    "    \n",
    "    entities = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith(\"Assistant:\"):\n",
    "            # Extract JSON content from assistant message\n",
    "            json_content = line.replace(\"Assistant:\", \"\").strip()\n",
    "            \n",
    "            # Skip non-JSON responses like \"I've read this text.\"\n",
    "            if json_content.startswith(\"{\") and json_content.endswith(\"}\"):\n",
    "                try:\n",
    "                    parsed_json = json.loads(json_content)\n",
    "                    # Extract entities only if their value is not an empty list\n",
    "                    for entity_key, entity_value in parsed_json.items():\n",
    "                        if entity_value != []:\n",
    "                            entities.append(entity_key)\n",
    "                except json.JSONDecodeError:\n",
    "                    # Skip malformed JSON\n",
    "                    continue\n",
    "    \n",
    "    return {\n",
    "        'entity_count': len(entities),\n",
    "        'entities': entities,\n",
    "        'entity_types': list(set(entities))  # Unique entity types\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_dataset_entities(dataset):\n",
    "    \"\"\"\n",
    "    Analyze all rows in dataset and provide entity statistics.\n",
    "    \n",
    "    Args:\n",
    "        dataset: HuggingFace dataset\n",
    "        \n",
    "    Returns:\n",
    "        dict: Statistics about entities across the dataset\n",
    "    \"\"\"\n",
    "    all_entities = []\n",
    "    entity_counts_per_row = []\n",
    "    \n",
    "    for row in dataset:\n",
    "        result = count_entities_per_row(row)\n",
    "        entity_counts_per_row.append(result['entity_count'])\n",
    "        all_entities.extend(result['entities'])\n",
    "    \n",
    "    entity_frequency = Counter(all_entities)\n",
    "    \n",
    "    return {\n",
    "        'total_rows': len(dataset),\n",
    "        'avg_entities_per_row': sum(entity_counts_per_row) / len(entity_counts_per_row) if entity_counts_per_row else 0,\n",
    "        'min_entities': min(entity_counts_per_row) if entity_counts_per_row else 0,\n",
    "        'max_entities': max(entity_counts_per_row) if entity_counts_per_row else 0,\n",
    "        'entity_frequency': dict(entity_frequency.most_common()),\n",
    "        'unique_entity_types': len(entity_frequency)\n",
    "    }\n",
    "\n",
    "\n",
    "# Test the function on a sample row\n",
    "sample_result = count_entities_per_row(processed_dataset[9])\n",
    "print(\"Sample row analysis:\")\n",
    "print(f\"Entity count: {sample_result['entity_count']}\")\n",
    "print(f\"Unique entity types: {sample_result['entity_types']}\")\n",
    "print(f\"\\nAll entities extracted: {sample_result['entities']}\")\n",
    "\n",
    "# Analyze the entire dataset\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Dataset-wide statistics:\")\n",
    "dataset_stats = analyze_dataset_entities(processed_dataset)\n",
    "for key, value in dataset_stats.items():\n",
    "    if key == 'entity_frequency':\n",
    "        print(f\"\\n{key}:\")\n",
    "        for entity, count in list(value.items())[:10]:  # Show top 10\n",
    "            print(f\"  {entity}: {count}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Extract all possible entities\n",
    "possible_entities = list(dataset_stats['entity_frequency'].keys())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"All possible entities ({len(possible_entities)} total):\")\n",
    "print(possible_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:11:48.535874Z",
     "iopub.status.busy": "2025-10-12T13:11:48.535492Z",
     "iopub.status.idle": "2025-10-12T13:11:49.279659Z",
     "shell.execute_reply": "2025-10-12T13:11:49.278774Z",
     "shell.execute_reply.started": "2025-10-12T13:11:48.535840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "target_modules=['up_proj', 'down_proj']  # Keep only the most essential ones\n",
    "\n",
    "    # target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:25:46.755147Z",
     "iopub.status.busy": "2025-10-12T13:25:46.754765Z",
     "iopub.status.idle": "2025-10-12T13:26:22.917152Z",
     "shell.execute_reply": "2025-10-12T13:26:22.916437Z",
     "shell.execute_reply.started": "2025-10-12T13:25:46.755112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/hussein/NER-Finetuning/.venv/lib/python3.13/site-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n",
      "/storage/hussein/NER-Finetuning/.venv/lib/python3.13/site-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "Adding EOS to train dataset: 100%|██████████| 9/9 [00:00<00:00, 1099.30 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 9/9 [00:00<00:00, 200.60 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 9/9 [00:00<00:00, 1463.53 examples/s]\n",
      "Adding EOS to eval dataset: 100%|██████████| 1/1 [00:00<00:00, 226.00 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 1/1 [00:00<00:00, 95.00 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 1/1 [00:00<00:00, 246.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# >= recommended versions\n",
    "#!pip -q install -U \"trl>=0.8.6\" \"transformers>=4.43.0\" \"peft>=0.12.0\" \"accelerate>=0.31.0\"\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# --- STEP 1: split ---\n",
    "data_split = processed_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_data = data_split[\"train\"]\n",
    "test_data  = data_split[\"test\"]\n",
    "\n",
    "# --- SFTConfig replaces TrainingArguments here ---\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=1,\n",
    "    # evaluation_strategy=\"steps\",   # valid here\n",
    "    # eval_steps=50,                 # must be int (e.g., every 50 steps)\n",
    "    logging_steps=1,\n",
    "    warmup_steps=2,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,                     # T4 => True; set False if you don’t have fp16\n",
    "    bf16=False,\n",
    "    group_by_length=False,         # set True later if you want; can spike VRAM\n",
    "    report_to=\"wandb\",\n",
    "    # max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    packing=False,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    #tokenizer=tokenizer,\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    peft_config=peft_config,\n",
    "    args=sft_config,               # ← pass SFTConfig here\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:26:22.918732Z",
     "iopub.status.busy": "2025-10-12T13:26:22.918484Z",
     "iopub.status.idle": "2025-10-12T13:53:06.728743Z",
     "shell.execute_reply": "2025-10-12T13:53:06.727996Z",
     "shell.execute_reply.started": "2025-10-12T13:26:22.918709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:53:18.422380Z",
     "iopub.status.busy": "2025-10-12T13:53:18.422016Z",
     "iopub.status.idle": "2025-10-12T13:53:18.904758Z",
     "shell.execute_reply": "2025-10-12T13:53:18.903814Z",
     "shell.execute_reply.started": "2025-10-12T13:53:18.422350Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-dragon-25</strong> at: <a href='https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset/runs/1xfjqy0b?apiKey=81c44037979e2da00170ba02dcb55a6018d51355' target=\"_blank\">https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset/runs/1xfjqy0b?apiKey=81c44037979e2da00170ba02dcb55a6018d51355</a><br> View project at: <a href='https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset?apiKey=81c44037979e2da00170ba02dcb55a6018d51355' target=\"_blank\">https://wandb.ai/charbeldaher34-lebanese-university/Fine-Tune%20Llama%203%208B%20on%20Crime%20Dataset?apiKey=81c44037979e2da00170ba02dcb55a6018d51355</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251022_064012-1xfjqy0b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: {'Evidence_Type': ['Rocks', 'glass fragments', 'security footage from a nearby ATM'], 'signature': ['Detective Emily Reed']}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "def infer_using_model(report_text, question, tokenizer, model, device):\n",
    "    \"\"\"\n",
    "    Uses a pre-trained model to process a crime report and infer answers to specific questions.\n",
    "    \n",
    "    Args:\n",
    "        report_text (str): The crime report to be processed.\n",
    "        question (str): The specific question to be answered from the report.\n",
    "        tokenizer (PreTrainedTokenizer): The tokenizer used to process the input.\n",
    "        model (PreTrainedModel): The pre-trained model for generating answers.\n",
    "        device (torch.device): The device where the model should run.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A JSON object containing the answer to the question.\n",
    "    \"\"\"\n",
    "    # Format the test prompt\n",
    "    test_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"A virtual assistant answers questions from a user based on the provided text, answer with a json object, key being the entity asked for by user and the value extracted from the text.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Text:\\n{report_text}\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"I’ve read this text.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(test_messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    # --- FIX: Isolate and decode only the newly generated tokens ---\n",
    "    input_token_length = inputs[\"input_ids\"].shape[1]\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=500, do_sample=False)\n",
    "\n",
    "    # Slice the output tensor to get only the new tokens\n",
    "    new_tokens = outputs[0, input_token_length:]\n",
    "    \n",
    "    # Decode just the new tokens\n",
    "    response_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "\n",
    "    # Extract json from response_text, get the text between the first and last curly braces\n",
    "    json_text = json.loads(f\"{{{response_text.split('{')[1].split('}')[0].strip()}}}\")\n",
    "\n",
    "\n",
    "    # Now handle the conversion of values to lists if needed\n",
    "    for key, value in json_text.items():\n",
    "        # If the value is a string and contains commas, split it\n",
    "        if isinstance(value, str) and ',' in value:\n",
    "            json_text[key] = [item.strip() for item in value.split(',')]\n",
    "        elif isinstance(value, str):  # If no comma, make it a list\n",
    "            json_text[key] = [value]\n",
    "\n",
    "    return response_text,json_text\n",
    "\n",
    "# Example usage\n",
    "new_report_text = \"\"\"\n",
    "**Crime Type:** Vandalism\n",
    "**Date and Time:** October 12, 2025, at 22:00\n",
    "**Location:** 101 Main Street, Springfield\n",
    "**Reporting Officer:** Detective Emily Reed\n",
    "**Summary:** The windows of the Springfield Public Library were shattered by rocks.\n",
    "**Description of Victim(s):** Springfield Public Library\n",
    "**Description of Suspect(s) (if applicable):** Two individuals in dark clothing seen fleeing the area.\n",
    "**Evidence Collected:** Rocks, glass fragments, security footage from a nearby ATM.\n",
    "**Current Status:** Under Investigation\n",
    "**Signature:** Detective Emily Reed\n",
    "\"\"\"\n",
    "\n",
    "question = \"What describes Evidence_Type and the signature in the text?\"\n",
    "\n",
    "# Assuming tokenizer, model, and device are already initialized\n",
    "response_text,json_text = infer_using_model(new_report_text, question, tokenizer, model, device)\n",
    "print(f\"Answer: {json_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Location\": [\n",
      "        \"456 Oakwood Drive, Rivertown\"\n",
      "    ],\n",
      "    \"Officer_BadgeNumber\": [\n",
      "        \"7421\"\n",
      "    ],\n",
      "    \"Officer_Name\": [\n",
      "        \"Officer Jane Thompson\"\n",
      "    ],\n",
      "    \"Victim_Name\": [\n",
      "        \"Rivertown Boutique\"\n",
      "    ],\n",
      "    \"Victim_Age\": [\n",
      "        34\n",
      "    ],\n",
      "    \"Victim_AgeRange\": [\n",
      "        \"Adult\"\n",
      "    ],\n",
      "    \"Victim_Owner\": [\n",
      "        \"Emily Carter\"\n",
      "    ],\n",
      "    \"Victim_Manager\": [],\n",
      "    \"Victim_CEO\": [],\n",
      "    \"Victim_Email\": [],\n",
      "    \"Crime_Time\": [\n",
      "        \"14:25\"\n",
      "    ],\n",
      "    \"Crime_Type\": [\n",
      "        \"Theft\"\n",
      "    ],\n",
      "    \"Crime_Summary\": [\n",
      "        \"A theft occurred at a local boutique, resulting in the loss of merchandise valued at approximately $1,500.\"\n",
      "    ],\n",
      "    \"Crime_Date\": [\n",
      "        \"September 30, 2025\"\n",
      "    ],\n",
      "    \"Crime_Status\": [\n",
      "        \"Under Investigation\"\n",
      "    ],\n",
      "    \"Evidence_Type\": [\n",
      "        \"Security camera footage\",\n",
      "        \"fingerprints from display cases\"\n",
      "    ],\n",
      "    \"Witness_Name\": [\n",
      "        \"None identified\"\n",
      "    ],\n",
      "    \"Suspect_Description\": [\n",
      "        \"Not provided\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    # Use a regex pattern to find all JSON-like structures in the text\n",
    "    json_matches = re.findall(r'(\\{.*?\\})', text, re.DOTALL)\n",
    "    \n",
    "    # Initialize a dictionary to store the final combined JSON\n",
    "    combined_json = {}\n",
    "\n",
    "    for match in json_matches:\n",
    "        # Convert the matched JSON string to a Python dictionary\n",
    "        try:\n",
    "            parsed_json = json.loads(match)\n",
    "            \n",
    "            # Add the parsed JSON to the combined_json dictionary\n",
    "            combined_json.update(parsed_json)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON: {match}\")\n",
    "    \n",
    "    return combined_json\n",
    "\n",
    "# Example usage:\n",
    "text = test_data[0][\"text\"]\n",
    "# print(text)\n",
    "# # Call the function with the provided text\n",
    "combined_json = extract_json_from_text(text)\n",
    "\n",
    "# # Print the combined JSON result\n",
    "print(json.dumps(combined_json, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text:\\n**Crime Type:** Theft  \\n**Date and Time:** September 30, 2025, at 14:25  \\n**Location:** 456 Oakwood Drive, Rivertown  \\n**Reporting Officer:** Officer Jane Thompson, Badge #7421  \\n**Summary:** A theft occurred at a local boutique, resulting in the loss of merchandise valued at approximately $1,500.  \\n**Description of Victim(s):** Rivertown Boutique, Owner: Emily Carter, 34 years old  \\n**Description of Suspect(s) (if applicable):** Not provided  \\n**Witnesses (if any):** None identified  \\n**Evidence Collected:** Security camera footage, fingerprints from display cases  \\n**Circumstances Surrounding the Incident:** At approximately 14:00, the boutique owner noticed several items missing from the display. Upon reviewing the security footage, it was observed that a male suspect entered the store pretending to browse and subsequently took several items before leaving without paying.  \\n**Initial Investigation:** Officer Thompson arrived on scene, collected evidence, and interviewed the victim. Security footage was secured for further analysis.  \\n**Further Steps:** Investigate the footage for identifiable features of the suspect and canvass the area for potential witnesses.  \\n**Current Status:** Under Investigation  \\n**Conclusion:** The investigation is ongoing, and efforts will continue to locate the suspect and retrieve the stolen goods.  \\n**Signature:** Officer Jane Thompson'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_report_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the first <|im_start|>user ... <|im_end|> section from a conversation text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input conversation text containing user/assistant/system blocks.\n",
    "\n",
    "    Returns:\n",
    "        str: The text content of the first user section, or an empty string if none found.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"<\\|im_start\\|>user\\s*(.*?)<\\|im_end\\|>\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"\"\n",
    "extract_report_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing model: 100%|██████████| 1/1 [00:34<00:00, 34.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'index': 0,\n",
       "  'document': 'Text:\\n**Crime Type:** Theft  \\n**Date and Time:** September 30, 2025, at 14:25  \\n**Location:** 456 Oakwood Drive, Rivertown  \\n**Reporting Officer:** Officer Jane Thompson, Badge #7421  \\n**Summary:** A theft occurred at a local boutique, resulting in the loss of merchandise valued at approximately $1,500.  \\n**Description of Victim(s):** Rivertown Boutique, Owner: Emily Carter, 34 years old  \\n**Description of Suspect(s) (if applicable):** Not provided  \\n**Witnesses (if any):** None identified  \\n**Evidence Collected:** Security camera footage, fingerprints from display cases  \\n**Circumstances Surrounding the Incident:** At approximately 14:00, the boutique owner noticed several items missing from the display. Upon reviewing the security footage, it was observed that a male suspect entered the store pretending to browse and subsequently took several items before leaving without paying.  \\n**Initial Investigation:** Officer Thompson arrived on scene, collected evidence, and interviewed the victim. Security footage was secured for further analysis.  \\n**Further Steps:** Investigate the footage for identifiable features of the suspect and canvass the area for potential witnesses.  \\n**Current Status:** Under Investigation  \\n**Conclusion:** The investigation is ongoing, and efforts will continue to locate the suspect and retrieve the stolen goods.  \\n**Signature:** Officer Jane Thompson',\n",
       "  'question': 'What describes Suspect_Description in the text?',\n",
       "  'ground_truth': {'Location': ['456 Oakwood Drive, Rivertown'],\n",
       "   'Officer_BadgeNumber': ['7421'],\n",
       "   'Officer_Name': ['Officer Jane Thompson'],\n",
       "   'Victim_Name': ['Rivertown Boutique'],\n",
       "   'Victim_Age': [34],\n",
       "   'Victim_AgeRange': ['Adult'],\n",
       "   'Victim_Owner': ['Emily Carter'],\n",
       "   'Victim_Manager': [],\n",
       "   'Victim_CEO': [],\n",
       "   'Victim_Email': [],\n",
       "   'Crime_Time': ['14:25'],\n",
       "   'Crime_Type': ['Theft'],\n",
       "   'Crime_Summary': ['A theft occurred at a local boutique, resulting in the loss of merchandise valued at approximately $1,500.'],\n",
       "   'Crime_Date': ['September 30, 2025'],\n",
       "   'Crime_Status': ['Under Investigation'],\n",
       "   'Evidence_Type': ['Security camera footage',\n",
       "    'fingerprints from display cases'],\n",
       "   'Witness_Name': ['None identified'],\n",
       "   'Suspect_Description': ['Not provided']},\n",
       "  'model_response': '<think>\\nOkay, the user is asking about the \"Suspect_Description\" in the provided text. Let me look through the text again to find that part.\\n\\nIn the text, after the \"Circumstances Surrounding the Incident\" section, there\\'s a line: \"At approximately 14:00, the boutique owner noticed several items missing from the display. Upon reviewing the security footage, it was observed that a male suspect entered the store pretending to browse and subsequently took several items before leaving without paying.\" \\n\\nSo the suspect is a male, and the description is \"male suspect\". The user probably wants the answer to be \"male suspect\" in the JSON format. I need to make sure there\\'s no other mention of the suspect\\'s details elsewhere, but I don\\'t see any other information about the suspect\\'s identity or description. So the correct answer should be \"male suspect\".\\n</think>\\n\\n{\\n  \"Suspect_Description\": \"male suspect\",\\n  \"Date and Time\": \"September 30, 2025, at 14:25\",\\n  \"Location\": \"456 Oakwood Drive, Rivertown\",\\n  \"Reporting Officer\": \"Officer Jane Thompson, Badge #7421\",\\n  \"Crime Type\": \"Theft\",\\n  \"Summary\": \"A theft occurred at a local boutique, resulting in the loss of merchandise valued at approximately $1,500\",\\n  \"Description of Victim(s)\": \"Rivertown Boutique, Owner: Emily Carter, 34 years old\",\\n  \"Evidence Collected\": \"Security camera footage, fingerprints from display cases\",\\n  \"Circumstances Surrounding the Incident\": \"At approximately 14:00, the boutique owner noticed several items missing from the display. Upon reviewing the security footage, it was observed that a male suspect entered the store pretending to browse and subsequently took several items before leaving without paying\",\\n  \"Initial Investigation\": \"Officer Thompson arrived on scene, collected evidence, and interviewed the victim. Security footage was secured for further analysis\",\\n  \"Further Steps\": \"Investigate the footage for identifiable features of the suspect and canvass the area for potential witnesses\",\\n  \"Current Status\": \"Under Investigation\",\\n  \"Conclusion\": \"The investigation is ongoing, and efforts will continue to locate the suspect and retrieve the stolen goods\"\\n}',\n",
       "  'predicted_json': {'Suspect_Description': ['male suspect'],\n",
       "   'Date and Time': ['September 30', '2025', 'at 14:25'],\n",
       "   'Location': ['456 Oakwood Drive', 'Rivertown'],\n",
       "   'Reporting Officer': ['Officer Jane Thompson', 'Badge #7421'],\n",
       "   'Crime Type': ['Theft'],\n",
       "   'Summary': ['A theft occurred at a local boutique',\n",
       "    'resulting in the loss of merchandise valued at approximately $1',\n",
       "    '500'],\n",
       "   'Description of Victim(s)': ['Rivertown Boutique',\n",
       "    'Owner: Emily Carter',\n",
       "    '34 years old'],\n",
       "   'Evidence Collected': ['Security camera footage',\n",
       "    'fingerprints from display cases'],\n",
       "   'Circumstances Surrounding the Incident': ['At approximately 14:00',\n",
       "    'the boutique owner noticed several items missing from the display. Upon reviewing the security footage',\n",
       "    'it was observed that a male suspect entered the store pretending to browse and subsequently took several items before leaving without paying'],\n",
       "   'Initial Investigation': ['Officer Thompson arrived on scene',\n",
       "    'collected evidence',\n",
       "    'and interviewed the victim. Security footage was secured for further analysis'],\n",
       "   'Further Steps': ['Investigate the footage for identifiable features of the suspect and canvass the area for potential witnesses'],\n",
       "   'Current Status': ['Under Investigation'],\n",
       "   'Conclusion': ['The investigation is ongoing',\n",
       "    'and efforts will continue to locate the suspect and retrieve the stolen goods']},\n",
       "  'is_correct': False}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def test_model_on_dataset(test_data = test_data, tokenizer = tokenizer, model = model, device = device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided test dataset.\n",
    "    \n",
    "    For each dataset row, this function:\n",
    "      1. Extracts the document (first <|im_start|>user ... <|im_end|> block)\n",
    "      2. Extracts the expected JSON output (ground truth)\n",
    "      3. Generates the model's response for each question\n",
    "      4. Extracts and compares predicted JSON with ground truth\n",
    "\n",
    "    Args:\n",
    "        test_data (list[dict]): The dataset rows, each with a 'text' key.\n",
    "        tokenizer: Hugging Face tokenizer\n",
    "        model: Hugging Face model\n",
    "        device: torch.device\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of test results containing document, question, \n",
    "                    model response, parsed JSON, ground truth, and correctness.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for idx, row in enumerate(tqdm(test_data, desc=\"Testing model\")):\n",
    "        text = row[\"text\"]\n",
    "\n",
    "        # Step 1: Extract document (the first user text)\n",
    "        document = extract_report_text(text)\n",
    "\n",
    "        # Step 2: Extract expected ground-truth JSON\n",
    "        ground_truth = extract_json_from_text(text)\n",
    "\n",
    "        # Step 3: Extract question (the *last* user message in the conversation)\n",
    "        question_match = re.findall(r\"<\\|im_start\\|>user\\s*(.*?)<\\|im_end\\|>\", text, re.DOTALL)\n",
    "        question = question_match[-1].strip() if len(question_match) > 1 else None\n",
    "\n",
    "        if not question or not document:\n",
    "            print(f\"Skipping row {idx} (missing question or document).\")\n",
    "            continue\n",
    "\n",
    "        # Step 4: Get model prediction\n",
    "        try:\n",
    "            response_text, predicted_json = infer_using_model(document, question, tokenizer, model, device)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error in row {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Step 5: Compare ground truth and predicted JSON\n",
    "        is_correct = (ground_truth == predicted_json)\n",
    "\n",
    "        # Step 6: Append structured results\n",
    "        results.append({\n",
    "            \"index\": idx,\n",
    "            \"document\": document,\n",
    "            \"question\": question,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"model_response\": response_text,\n",
    "            \"predicted_json\": predicted_json,\n",
    "            \"is_correct\": is_correct\n",
    "        })\n",
    "\n",
    "    return results\n",
    "test_model_on_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "All possible entities (16 total):\n",
      "['Officer_BadgeNumber', 'Officer_Name', 'Crime_Time', 'Crime_Type', 'Crime_Summary', 'Crime_Date', 'Crime_Status', 'Evidence_Type', 'Suspect_Description', 'Victim_Name', 'Witness_Name', 'Location', 'Victim_Owner', 'Victim_Age', 'Victim_AgeRange', 'Victim_Manager']\n"
     ]
    }
   ],
   "source": [
    "possible_entities = list(dataset_stats['entity_frequency'].keys())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"All possible entities ({len(possible_entities)} total):\")\n",
    "print(possible_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5588475,
     "sourceId": 9238853,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5626745,
     "sourceId": 9293892,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5664700,
     "sourceId": 9346157,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5708173,
     "sourceId": 9402840,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8385552,
     "sourceId": 13229217,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 1902,
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 39106,
     "modelInstanceId": 28500,
     "sourceId": 34046,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
